# Main Takeaway

矩阵分析 or 矩阵论

聚焦理论深化，为泛函分析铺垫

这一节主要介绍《矩阵论》——戴华 第一/二章，线性空间与内积空间，线性映射与线性变换

<!--more-->

# Intro

从线性代数到矩阵分析，从低级到高级，由线性变换（几何思想）到矩阵（代数思想）

我们先来分析一下**线性代数**这四个字，也即线性+代数，然后过渡到矩阵分析

下面我们来看一个初中称为四元一次方程的方程
$$
x_1+x_2+x_3+x_4 = 0
$$
大学称其为四元一次线性齐次不定方程

- 四元一次：线性的对象，共四个对象

- 线性：1、对象，2、计算结构（数乘和加法），能够得到线性相关（组合）

  线性系统：$2A+3B$是，$A\times B$不是

- 齐次

- 不定（大学牲）：用秩来描述。

  那么秩有很多形式

  - 极大无关组的个数称为秩

  - 基（从极大无关组到空间）的个数称为维度（秩）

  - 一个矩阵的秩是其非零子式的最高阶数（行列式定义），或等价地，是矩阵对应的线性映射的像的维度（线性映射定义）

    为什么有这个定义，因为线性代数的四则运算，我们需要解决除法的问题：
    $$
    A \div B \stackrel{}{\Longrightarrow} A \frac{1}{B}  \stackrel{}{\Longrightarrow} AB^{-1} \stackrel{}{\Longrightarrow}逆 \stackrel{}{\Longrightarrow}可逆  \stackrel{度量}{\Longrightarrow}行列式 \stackrel{}{\Longrightarrow}(满)秩
    $$

明明是线性（$\pm$）和非线性（$\times,\div$），为什么要叫线性代数？奥妙在于
$$
2x+3y+4z \text{(线性结构)} = 
\begin{bmatrix}
2&3&4
\end{bmatrix}
\begin{bmatrix}
x\\
y\\
z
\end{bmatrix} \text{非线性结构}
$$
**使用一个非线性的乘法结构反映一个线性结构**——思考问题用乘法

学好数学的两大方法

1. 过河拆桥：$\text{what}\longrightarrow\text{why(丢弃)}\longrightarrow \text{how} $

   上面我们已经得到矩阵的**乘法**了（不管why），下面要将乘法返回去

2. 返回去
   $$
   \text{乘法} \stackrel{反向}{\Longrightarrow}研究矩阵 \\ \stackrel{简化}{\Longrightarrow} 
    \begin{cases}
   等价:\exist P,Q, ~s.t. ~PAQ = B,则A与B等价 \\
   相似:\exist P ~s.t. ~P^{-1}AP = B,则A与B相似 \\
   合同:\exist P, ~s.t. ~P^{\top}AP = B,则A与B合同
   
   \end{cases}
   \\
   \stackrel{保留的性质}{\Longrightarrow}  
    \begin{cases}
   等价:不变特性r(A) = r(B) \\
   相似:r(A) = r(B),特征值(向量) \\
   合同:r(A) = r(B),惯性{\Longrightarrow} 定性(载体二次型)
   
   \end{cases}
   $$

   > Tips：为什么是简化？我们希望矩阵是简化的，但是特征是保留的

   三者的关系：

   ![image-20250622223311820](./assets/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4.assets/image-20250622223311820.png)

   我们研究最特殊的部分：
   $$
   P^{-1} = P^{\top}\stackrel{}{\Longrightarrow}正交矩阵\stackrel{}{\Longrightarrow}正交是几何概念\stackrel{}{\Longrightarrow}垂直的推广\stackrel{}{\Longrightarrow}内积
   $$
   然后我们来看详细的部分：$~P^{-1}AP = B\stackrel{}{\Longrightarrow} AP = PB$

   其中$B$为对角特征值矩阵，$P$为特征向量，其核心价值在于：
   $$
   P^{-1} A^nP = \begin{bmatrix}
   \lambda_1^n & &\\
   & \lambda_2^n &\\
   & & \lambda_3^n
   
   \end{bmatrix} \stackrel{}{\Longrightarrow} A^n =P\begin{bmatrix}
   \lambda_1^n & &\\
   & \lambda_2^n &\\
   & & \lambda_3^n
   
   \end{bmatrix}P^{-1}
   $$
   也即$x^n$幂级数。有了幂级数我们就能得到各种函数的表达（泰勒展开）

下面给一个例子：
$$
A = \begin{bmatrix}
1& 1\\
1& 1

\end{bmatrix},\quad \exist P^{-1}AP = \begin{bmatrix}
0&\\
& 2

\end{bmatrix}
$$

$$
e^{A} = P\begin{bmatrix}
\exp(0)&\\
& \exp(2)

\end{bmatrix}P^{-1}
$$

于是我们就来到了**矩阵分析**：以矩阵（线性代数）+分析（数学分析）为基础，以矩阵函数为对象，以极限为工具，研究对象的四则运算

> 这里我们同时看看高等数学（偏重于计算）到数学分析（计算，理论）
>
> 分析：工具是极限，分析对象是四则运算。高等高在：
>
> - 微：$近\stackrel{距离}{\Longrightarrow}绝对值\stackrel{}{\Longrightarrow}极限$
> - 无穷次
>
> 为什么是四则运算：微分（$dx = (x+dx) - x$为减法），积分（sum:$\int$为加法），导数（$f'(x) = \frac{df(x)}{dx}$为除法），乘法（因为$df(x)$很难求，所以计算时利用导数来得到$df(x) = f'(x)dx$变为乘法）

还有不一样的地方，线代中我们研究的都是实矩阵，在矩阵分析中我们要研究复数$C$，矩阵$A$元素为复数就成为复矩阵，定义了一个运算：
$$
A^H =\overline{ A^{\top}} =\overline{ A}^{\top}
$$


# 线性空间与内积空间

本章概述线性空间与内积空间的基本概念和基本理论

## 预备知识

预备知识：集合、映射与数域

### 集合及其运算

有限集，无限集，

### 二元关系与等价关系

- Descartes积：设 $A, B$ 是两个非空集合, 元素对的集合 $\{(a, b) \mid a \in A, b \in B\}$ 称为 $A$ 与 $B$ 的 **Descartes 积**, 记作 $A \times B$, 即$$A \times B = \{(a, b) \mid a \in A, b \in B\}.$$
  
  例如，设 $A = \{1, 2, 3\}, B = \{a, b\}$, 则
  $$
  A \times B = \{(1, a), (1, b), (2, a), (2, b), (3, a), (3, b)\}.
  $$
  
- 定义：如果集合 $A$ 上的一个二元关系 $R$ 满足
  - 自反性：对任意 $a \in A$，有 $aRa$；
  - 对称性：对任意 $a, b \in A$，如果 $aRb$，则 $bRa$；
  - 传递性：对任意 $a, b, c \in A$，如果 $aRb, bRc$，则 $aRc$，
  
  则称 $R$ 是 $A$ 上的一个**等价关系**

  例如，实数集 $\mathbb{R}$ 上的相等"="是 $\mathbb{R}$ 上的等价关系

- 定义：设 $R$ 是 $A$ 上的一个等价关系，$a \in A$，称 $[a] = \{x \mid x \in A, xRa\}$ 为 $a$ 关于 $R$ 的等价类。$A$ 的所有元素关于 $R$ 的等价类集合 $A/R = \{[a] \mid a \in A\}$ 称为 $A$ 关于 $R$ 的商集。

- 定义：设每个 $B_i$ ($i \in I$) 都是集合 $A$ 的非空子集，如果 $A = \bigcup_{i \in I} B_i$，并且对任意 $i, j \in I$，当 $i \neq j$ 时有 $B_i \cap B_j = \emptyset$，则称 $\{B_i\}$ 是 $A$ 的一个分类。


下面的定理建立了集合的分类与等价关系之间的联系。

- 定理：
  - 集合 $A$ 上的每个等价关系 $R$ 都决定 $A$ 的一个分类
  - 集合 $A$ 的每个分类都决定 $A$ 上的一个等价关系

### 映射



### 数域与代数运算

- 数域：设P是包含0和1在内的数集，如果P中任意两个数的和、差、积、商（除数不为0)仍是P中的数，则称P为一个数域
- 代数运算：设A，B，C是三个非空集合，A×B到C的映射称为A与B到C的一个代数运算。特别地，A×A到C的映射称为A到C的代数运算；A×A到A的映射称为A的代数运算或A的二元运算，也称集合A对代数运算是封闭的





## 线性空间

- 线性空间及其基本性质

  线性空间时向量空间的自然推广，线性空间中的元素也称为向量，满足加法和数乘

  定理：设 $  V  $ 是数域 $  \mathbf{P}  $ 上的线性空间, 则

  1.  $  V  $ 中零元素是唯一的；
  2. $  V  $ 中任一元素 $  \alpha  $ 的负元素是唯一的；
  3. $  0 \cdot \alpha = 0, \, k \cdot 0 = 0, \, (-1) \cdot \alpha = -\alpha  $；
  4. 如果 $  k \cdot \alpha = 0  $, 那么 $  k = 0  $ 或者 $  \alpha = 0  $.

- 向量的线性相关性

  线性表达（线性组合）。线性空间中的一组向量其极大线性无关组的个数为向量组的秩

- 线性空间的维数

## 基与坐标

设 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 与 $  \varepsilon_1', \varepsilon_2', \cdots, \varepsilon_n'  $ 是 $  n  $ 维线性空间 $  V  $ 的两组基, 它们之间有如下关系

$$
\begin{cases}\varepsilon_1' = t_{11} \varepsilon_1 + t_{21} \varepsilon_2 + \cdots + t_{n1} \varepsilon_n \\\varepsilon_2' = t_{12} \varepsilon_1 + t_{22} \varepsilon_2 + \cdots + t_{n2} \varepsilon_n \\\quad \quad \vdots\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad   \\ \varepsilon_n' = t_{1n} \varepsilon_1 + t_{2n} \varepsilon_2 + \cdots + t_{nn} \varepsilon_n\end{cases}
$$
用矩阵记号可表示为

$$
(\varepsilon_1', \varepsilon_2', \cdots, \varepsilon_n') = (\varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n)\begin{bmatrix}t_{11} & t_{12} & \cdots & t_{1n} \\t_{21} & t_{22} & \cdots & t_{2n} \\\vdots & \vdots &        & \vdots \\t_{n1} & t_{n2} & \cdots & t_{nn}\end{bmatrix}
$$
$  n  $ 阶矩阵$$T = \begin{bmatrix}t_{11} & t_{12} & \cdots & t_{1n} \\t_{21} & t_{22} & \cdots & t_{2n} \\\vdots & \vdots &        & \vdots \\t_{n1} & t_{n2} & \cdots & t_{nn}\end{bmatrix}$$称为由基 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 到基 $  \varepsilon_1', \varepsilon_2', \cdots, \varepsilon_n'  $ 的过渡矩阵。

容易证明: 过渡矩阵 $  T  $ 是可逆的.



## 线性子空间

- 线性子空间

  - 线性子空间关于加法和数乘是封闭的

  - 线性空间$V$的每个子空间都是凸集：零子空间为子集$\{0\}$，零子空间和线性空间$V$都为$V$的平凡子空间，$V$的其它子空间称为非平凡子空间

    例 ：设 $  A \in \mathbb{R}^{m \times n}  $, 齐次线性方程组$$Ax = 0$$的全部解向量构成 $  n  $ 维线性空间 $  \mathbb{R}^n  $ 的一个子空间. 这个子空间称为齐次线性方程组的解空间或矩阵 $  A  $ 的 **零空间 (核)**, 记为 $  N(A)  $ 或 $  \text{Ker}(A)  $. 因为解空间的基就是齐次线性方程组的基础解系, 所以 $  \dim(N(A)) = n - \text{rank}(A)  $

  - 张成的子空间：

    设 $  \alpha_1, \alpha_2, \cdots, \alpha_s  $ 是数域 $  \mathbf{P}  $ 上线性空间 $  V  $ 的一组向量, 这个向量组的所有线性组合作成的集合记为 $  W  $, 即$$W = \{ k_1 \alpha_1 + k_2 \alpha_2 + \cdots + k_s \alpha_s \mid k_i \in \mathbf{P}, i = 1, \cdots, s \}$$显然，$  W  $ 是 $  V  $ 的非空子集且 $  W  $ 是 $  V  $ 的子空间. 我们称 $  W  $ 是由向量 $  \alpha_1, \alpha_2, \cdots, \alpha_s  $ **生成 (或张成)** 的子空间, 记为 $  L(\alpha_1, \alpha_2, \cdots, \alpha_s)  $ 或 $  \text{span}(\alpha_1, \alpha_2, \cdots, \alpha_s)  $

    > 注意这里不一定是基，这个向量组的基张成的空间和向量组张成的空间是一样

    例：设 $  A \in \mathbb{R}^{m \times n}  $, 记 $  A = [\alpha_1, \alpha_2, \cdots, \alpha_n]  $, 其中 $  \alpha_i \in \mathbb{R}^m \, (i = 1, \cdots, n)  $, 则 $  \text{span}(\alpha_1, \cdots, \alpha_n)  $ 是 $  m  $ 维线性空间 $  \mathbb{R}^m  $ 的一个子空间, 称为矩阵 $  A  $ 的 **列空间 (值域)**, 记为 $  R(A)  $ 或 $  \text{span}(A)  $. $  R(A)  $ 可表成

    $$R(A) = \{ y \mid y = Ax, x \in \mathbb{R}^n \}$$

    知 $  \dim(R(A)) = \text{rank}(A)  $, 并且 $  \dim(N(A)) + \dim(R(A)) = n  $

- 子空间的交与和

  - 定理：设 $  V_1, V_2  $ 是数域 $  \mathbf{P}  $ 上线性空间 $  V  $ 的两个子空间, 则它们的交 $  V_1 \cap V_2  $ 也是 $  V  $ 的子空间，但是他们的并不一定是$V$的子空间（可能不满足加法封闭性）

    于是我们提出了子空间的和：设 $  V_1, V_2  $ 是数域 $  \mathbf{P}  $ 上线性空间 $  V  $ 的两个子空间, 则集合$$\{ \alpha_1 + \alpha_2 \mid \alpha_1 \in V_1, \alpha_2 \in V_2 \}$$称为 $  V_1  $ 与 $  V_2  $ 的和，记为 $  V_1 + V_2  $

    > 显然 $  V_1 \cup V_2 \subseteq V_1 + V_2  $

    子空间的交与和均满足交换律和结合律

  - 维数公式：设 $  V_1, V_2  $ 是数域 $  \mathbf{P}  $ 上线性空间 $  V  $ 的两个有限维子空间, 则 $  V_1 \cap V_2  $ 与 $  V_1 + V_2  $ 都是有限维的，并且$$\dim(V_1) + \dim(V_2) = \dim(V_1 + V_2) + \dim(V_1 \cap V_2)$$

    由维数公式可知, 线性空间的两个有限维子空间之和的维数往往小于这两个子空间的维数之和。两个子空间之和的维数等于它们维数之和的情形是特别重要的，这样的两个子空间之和称为**直和**

- 子空间的直和

  - 定义：设 $  V_1, V_2  $ 是数域 $  \mathbf{P}  $ 上线性空间 $  V  $ 的两个子空间, 如果和 $  V_1 + V_2  $ 中每个向量 $  \alpha  $ 可唯一地表示成$$\alpha = \alpha_1 + \alpha_2, \quad \alpha_1 \in V_1, \alpha_2 \in V_2$$则称和 $  V_1 + V_2  $ 为 **直和**，记为 $  V_1 \dot{+} V_2  $
  - 定理：设 $  V_1, V_2  $ 是数域 $  \mathbf{P}  $ 上线性空间 $  V  $ 的两个子空间, 则下面的叙述是等价的
    1. 和 $  V_1 + V_2  $ 是直和；
    2. 和 $  V_1 + V_2  $ 中零向量的表示法唯一，即若 $  \alpha_1 + \alpha_2 = 0 \, (\alpha_1 \in V_1, \alpha_2 \in V_2)  $, 则 $  \alpha_1 = 0, \alpha_2 = 0  $；
    3. $  V_1 \cap V_2 = \{0\}  $；
    4. $  \dim(V_1 + V_2) = \dim(V_1) + \dim(V_2)  $
  - 定理：设 $  U  $ 是数域 $  \mathbf{P}  $ 上有限维线性空间 $  V  $ 的一个子空间, 则存在 $  V  $ 的一个子空间 $  W  $ 使得 $  V = U \dot{+} W  $.

## 线性空间的同构

- 定义：设 $  V  $ 与 $  V'  $ 都是数域 $  \mathbf{P}  $ 上的线性空间, 如果存在 $  V  $ 到 $  V'  $ 上的一一映射 $  \sigma  $ 满足

  1. $  \sigma(\alpha + \beta) = \sigma(\alpha) + \sigma(\beta)  $；
  2. $  \sigma(k\alpha) = k\sigma(\alpha)  $，

  其中 $  \alpha, \beta  $ 是 $  V  $ 中任意向量, $  k  $ 是数域 $  \mathbf{P}  $ 中任意数, 则称 $  \sigma  $ 为 $  V  $ 到 $  V'  $ 的 **同构映射**, 并且称 $  V  $ 与 $  V'  $ 是 **同构** 的



## 内积空间

- 内积空间及其基本性质

  - 定义：设 $  V  $ 是数域 $  \mathbf{P}  $ 上的线性空间, $  V  $ 到 $  \mathbf{P}  $ 的一个代数运算记为 $  (\alpha, \beta)  $。如果 $  (\alpha, \beta)  $ 满足下列条件：

    (1) $  (\alpha, \beta) = \overline{(\beta, \alpha)}  $；

    (2) $  (\alpha + \beta, \gamma) = (\alpha, \gamma) + (\beta, \gamma)  $；

    (3) $  (k\alpha, \beta) = k(\alpha, \beta)  $；

    (4) $  (\alpha, \alpha) \geq 0  $，当且仅当 $  \alpha = 0  $ 时 $  (\alpha, \alpha) = 0  $，

    其中 $  k  $ 是数域 $  \mathbf{P}  $ 中的任意数, $  \alpha, \beta, \gamma  $ 是 $  V  $ 中的任意向量, 则称 $  (\alpha, \beta)  $ 为 $  \alpha  $ 与 $  \beta  $ 的 **内积**。定义了内积的线性空间 $  V  $ 称为 **内积空间**。特别地, 称实数域 $  \mathbf{R}  $ 上的内积空间 $  V  $ 为 **Euclid 空间**（简称为 **欧氏空间**）；称复数域 $  \mathbf{C}  $ 上的内积空间 $  V  $ 为 **酉空间**

  - 长度定义：设 $  V  $ 是内积空间, $  V  $ 中向量 $  \alpha  $ 的 **长度** 定义为 $  \|\alpha\| = \sqrt{(\alpha, \alpha)}  $

    长度为 1 的向量称为 **单位向量**，如果 $  \alpha \neq 0  $, 则 $  \frac{\alpha}{\|\alpha\|}  $ 是一个单位向量。这样定义的向量长度与几何空间中向量的长度是一致的

  - 定义：设 $  V  $ 是内积空间, $  V  $ 中向量 $  \alpha  $ 与 $  \beta  $ 之间的 **距离** 定义为$$d(\alpha, \beta) = \|\alpha - \beta\| \tag{1.6}$$，并称 $  d(\alpha, \beta) = \|\alpha - \beta\|  $ 是由长度导出的距离

  - 度量矩阵：

    设 $  V  $ 是数域 $  \mathbf{P}  $ 上的 $  n  $ 维内积空间, $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 是 $  V  $ 的一组基. 对任意 $  \alpha, \beta \in V  $, 有

    $$\alpha = x_1 \varepsilon_1 + x_2 \varepsilon_2 + \cdots + x_n \varepsilon_n, \quad \beta = y_1 \varepsilon_1 + y_2 \varepsilon_2 + \cdots + y_n \varepsilon_n$$

    则 $  \alpha  $ 与 $  \beta  $ 的内积

    $$
    (\alpha, \beta) = \left( \sum_{i=1}^n x_i \varepsilon_i, \sum_{j=1}^n y_j \varepsilon_j \right) = \sum_{i=1}^n \sum_{j=1}^n (\varepsilon_i, \varepsilon_j) x_i \overline{y}_j
    $$
    令$$a_{ij} = (\varepsilon_i, \varepsilon_j), \quad i, j = 1, 2, \cdots, n$$，则

    $$
    A = \begin{bmatrix}a_{11} & a_{12} & \cdots & a_{1n} \\a_{21} & a_{22} & \cdots & a_{2n} \\\vdots & \vdots &        & \vdots \\a_{n1} & a_{n2} & \cdots & a_{nn}\end{bmatrix}, \quad x = \begin{bmatrix}x_1 \\x_2 \\\vdots \\x_n\end{bmatrix}, \quad y = \begin{bmatrix}y_1 \\y_2 \\\vdots \\y_n\end{bmatrix}
    $$
    称矩阵 $  A  $ 为基 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 的 **度量矩阵**，显然 $  a_{ij} = \overline{a_{ji}} \, (i, j = 1, 2, \cdots, n)  $, 并且$$(\alpha, \beta) = y^H A x \tag{1.6.12}$$

    定理：设 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 是数域 $  \mathbf{P}  $ 上 $  n  $ 维内积空间 $  V  $ 的一组基, 则它的度量矩阵 $  A  $ 非奇异

  - 共轭转置矩阵：设 $  A \in \mathbb{C}^{m \times n}  $, 用 $  \bar{A}  $ 表示以 $  A  $ 的元素的共轭复数为元素组成的矩阵, $  A^H = (\bar{A})^T  $ 称为 $  A  $ 的 **共轭转置矩阵**

  - Hermite矩阵：设 $  A \in \mathbb{C}^{n \times n}  $, 如果 $  A^H = A  $, 则称 $  A  $ 为 **Hermite 矩阵**；如果 $  A^H = -A  $, 则称 $  A  $ 为 **反 Hermite 矩阵**

    实对称矩阵是 Hermite 矩阵，有限维内积空间的度量矩阵是 Hermite 矩阵

  - 相合：设 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 与 $  \varepsilon_1', \varepsilon_2', \cdots, \varepsilon_n'  $ 是数域 $  \mathbf{P}  $ 上 $  n  $ 维内积空间 $  V  $ 的两组基, 它们的度量矩阵分别为 $  A  $ 和 $  B  $, 并且基 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 到基 $  \varepsilon_1', \varepsilon_2', \cdots, \varepsilon_n'  $ 的过渡矩阵为 $  P  $, 则 $  B = P^H A P  $。

    若存在$n$阶非奇异矩阵$P$，使得$  B = P^H A P  $则称两者是相合的（相合是等价关系）

- 标准正交基与Gram-Schmidt正交化方法

  正交向量组，标准正交向量组，充要条件为：$(a_i,a_j) = 0,i\ne j$。标准正交基

  - 定理：设 $  \alpha_1, \alpha_2, \cdots, \alpha_m  $ 是内积空间 $  V  $ 中的一个向量组, 则 $  \alpha_1, \alpha_2, \cdots, \alpha_m  $ 线性无关的充分必要条件是矩阵

    $$
    G(\alpha_1, \alpha_2, \cdots, \alpha_m) = \begin{bmatrix}(\alpha_1, \alpha_1) & (\alpha_1, \alpha_2) & \cdots & (\alpha_1, \alpha_m) \\(\alpha_2, \alpha_1) & (\alpha_2, \alpha_2) & \cdots & (\alpha_2, \alpha_m) \\\vdots & \vdots &        & \vdots \\(\alpha_m, \alpha_1) & (\alpha_m, \alpha_2) & \cdots & (\alpha_m, \alpha_m)\end{bmatrix}
    $$
    非奇异

    矩阵$G(\alpha_1, \alpha_2, \cdots, \alpha_m)$称为向量组的Gram矩阵

  - Gram-Schmidt正交化：

    我们由 $  \alpha_1, \alpha_2, \cdots, \alpha_n  $ 逐个地求出标准正交向量组 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $，令$$\varepsilon_1 = \frac{\alpha_1}{\|\alpha_1\|}$$

    则 $  \varepsilon_1  $ 是单位向量, 并且 $  \text{span}(\alpha_1) = \text{span}(\varepsilon_1)  $

    一般地, 假定已经求出标准正交向量 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_m  $, 并且

    $$
    \text{span}(\alpha_1, \alpha_2, \cdots, \alpha_m) = \text{span}(\varepsilon_1, \varepsilon_2, \cdots, \varepsilon_m), \quad m = 1, 2, \cdots, n
    $$
    下一步求 $  \varepsilon_{m+1}  $ 作向量$$\beta_{m+1} = \alpha_{m+1} - k_1 \varepsilon_1 - k_2 \varepsilon_2 - \cdots - k_m \varepsilon_m$$，其中 $  k_1, k_2, \cdots, k_m  $ 待定常数，选取$$k_i = (\alpha_{m+1}, \varepsilon_i), \quad i = 1, 2, \cdots, m$$

    则 $  (\beta_{m+1}, \varepsilon_i) = 0 \, (i = 1, 2, \cdots, m)  $. 因为 $  \beta_{m+1} \neq 0  $, 并且 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_m, \beta_{m+1}  $ 是正交向量组，令$$\varepsilon_{m+1} = \frac{\beta_{m+1}}{\|\beta_{m+1}\|}$$

    则 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_m, \varepsilon_{m+1}  $ 是标准正交向量组, 并且$$\text{span}(\alpha_1, \alpha_2, \cdots, \alpha_{m+1}) = \text{span}(\varepsilon_1, \varepsilon_2, \cdots, \varepsilon_{m+1})$$

    上述把一组线性无关向量变成标准正交向量组的方法常称为 **Gram-Schmidt 正交化方法**

  - 在标准正交基下，**向量的坐标和内积**有特别简单的表达式. 设 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 是 $  n  $ 维内积空间 $  V  $ 的一组标准正交基, 则对任意 $  \alpha \in V  $ 都有

    $$
    \alpha = (\alpha, \varepsilon_1) \varepsilon_1 + (\alpha, \varepsilon_2) \varepsilon_2 + \cdots + (\alpha, \varepsilon_n) \varepsilon_n 
    $$
    并且对任意 $  \alpha, \beta \in V  $, 如果$$\alpha = x_1 \varepsilon_1 + x_2 \varepsilon_2 + \cdots + x_n \varepsilon_n, \quad \beta = y_1 \varepsilon_1 + y_2 \varepsilon_2 + \cdots + y_n \varepsilon_n \tag{1.6.14}$$，则

    $$
    (\alpha, \beta) = \sum_{i=1}^n x_i \overline{y}_i 
    $$
    该表达式是解析几何中向量内积表达式的推广

- 正交补与投影定理

  - 正交和：子空间正交，两个子空间如果正交则其和为直和，也称为**正交和**

  - 正交补：设 $  V_1  $ 是内积空间 $  V  $ 的一个子空间, $  V  $ 中所有与 $  V_1  $ 正交的向量所成的集合记为 $  V_1^\perp  $, 即 $  V_1^\perp = \{ \alpha \in V \mid \alpha \perp V_1 \}  $, 则称 $  V_1^\perp  $ 为 $  V_1  $ 的 **正交补**

    > 如果$V_1$为有限维子空间，则有唯一正交补

  - 正交投影与投影定理：设 $  V_1  $ 是内积空间 $  V  $ 的一个子空间, $  \alpha \in V  $, 如果有 $  \alpha_1 \in V_1, \alpha_2 \perp V_1  $ 使得

    $$\alpha = \alpha_1 + \alpha_2$$，则称 $  \alpha_1  $ 是 $  \alpha  $ 在 $  V_1  $ 上的 **正交 (直交) 投影**.

    投影定理：设 $  V_1  $ 是内积空间 $  V  $ 的有限维子空间, 则对任意 $  \alpha \in V  $, $  \alpha  $ 在 $  V_1  $ 上的正交投影存在并且唯一

  - 最佳逼近：$\alpha$在$V_1$上的最佳逼近就是$\alpha$在$V_1$上的正交投影



# 线性映射与线性变换



## 线性映射及其矩阵表示

- 线性映射定义与性质

  - 定义：从一个线性空间到另一个线性空间的映射，满足数乘和加法则为线性映射（线性算子）

    > 线性映射也称同态映射比同构映射更广泛（不需要单射和漫射的条件）

  - 性质：线性映射由基像组唯一确定

  - 计算：线性映射也有乘法和加法运算，有数乘

    有限维线性空间 $  V_1  $ 到 $  V_2  $ 的可逆线性映射存在的充分必要条件是 $  \dim(V_1) = \dim(V_2)  $

- 线性映射的矩阵表示

  - 定理：设 $  V_1  $ 是数域 $  \mathbf{P}  $ 上的 $  n  $ 维线性空间, $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 是 $  V_1  $ 的一组基, $  V_2  $ 是数域 $  \mathbf{P}  $ 上的 $  m  $ 维线性空间, $  \eta_1, \eta_2, \cdots, \eta_m  $ 是 $  V_2  $ 的一组基, 则 $  V_1  $ 到 $  V_2  $ 的每一个线性映射与它在基 $  \varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n  $ 和基 $  \eta_1, \eta_2, \cdots, \eta_m  $ 下的矩阵之间的对应 $  \sigma  $ 是线性空间 $  \mathcal{L}(V_1, V_2)  $ 到 $  \mathbf{P}^{m \times n}  $ 的同构映射, 从而 $  \mathcal{L}(V_1, V_2)  $ 与 $  \mathbf{P}^{m \times n}  $ 同构

    可以看出选择不一样的基得到的线性映射对应的矩阵不一样，那么在不同的基下面得到的矩阵的关系是什么？这里就需要相抵的概念：

  - 相抵定义：设 $  A, B \in \mathbb{P}^{m \times n}  $，如果存在数域 $  \mathbb{P}  $ 上的 $  m  $ 阶非奇异矩阵 $  P  $ 和 $  n  $ 阶非奇异矩阵 $  Q  $ 使得$$B = PAQ$$，则称 $  A  $ 与 $  B  $ **相抵**。相抵是一个等价关系

    定理：设 $  A \in \mathbb{P}^{m \times n}  $ 且 $  \text{rank}(A) = r \geq 1  $，则存在 $  m  $ 阶可逆矩阵 $  P  $ 和 $  n  $ 阶可逆矩阵 $  Q  $ 使得

    $$
    A = P \begin{bmatrix} I_r & 0 \\ 0 & 0 \end{bmatrix} Q,\quad \begin{bmatrix} I_r & 0 \\ 0 & 0 \end{bmatrix}为A的相抵标准形
    $$
    可知，对一个线性映射 $  \mathcal{A}  $ 可以选取一对适当的基，使它在这对基下的矩阵具有最简单的形式——相抵标准形。

    - 定理：设 $  A, B \in \mathbb{P}^{m \times n}  $，则 $  A  $ 与 $  B  $ 相抵的充分必要条件是它们有相同的秩。



## 线性映射的值域与核

本节讨论伴随线性映射的两类重要子空间：线性映射的值域与核

- 定义：设 $  \mathcal{A}  $ 是数域 $  \mathbb{P}  $ 上线性空间 $  V_1  $ 到 $  V_2  $ 的线性映射，令
  $$
  R(\mathcal{A}) = I_m(\mathcal{A}) = \{ \mathcal{A}(\alpha) \mid \alpha \in V_1 \} \\
  \text{Ker}(\mathcal{A}) = N(\mathcal{A}) = \{ \alpha \in V_1 \mid \mathcal{A}(\alpha) = 0 \}
  $$
  称 $  R(\mathcal{A})  $ 是线性映射 $  \mathcal{A}  $ 的值域；而称 $  \text{Ker}(\mathcal{A})  $ 是线性映射 $  \mathcal{A}  $ 的核

- 定理：设 $  \mathcal{A}  $ 是线性空间 $  V_1  $ 到 $  V_2  $ 的一个线性映射，则

  1. $  R(\mathcal{A})  $ 是 $  V_2  $ 的一个子空间；
  2. $  \text{Ker}(\mathcal{A})  $ 是 $  V_1  $ 的一个子空间。

  $$\dim(R(\mathcal{A})) \text{称为 } \mathcal{A} \text{的秩，记为 } \text{rank}(\mathcal{A}) ; \dim(\text{Ker}(\mathcal{A})) \text{称为 } \mathcal{A} \text{的零度}.$$

  有了各自的定义，我们来看看他们之间的关系

- 定理：设 $  \mathcal{A}  $ 是 $  n  $ 维线性空间 $  V_1  $ 到 $  m  $ 维线性空间 $  V_2  $ 的一个线性映射，$  \epsilon_1, \cdots, \epsilon_n  $ 和 $  \eta_1, \cdots, \eta_m  $ 分别是 $  V_1  $ 与 $  V_2  $ 的基，$  \mathcal{A}  $ 在这对基下的矩阵是 $  A  $，则

  1. $  R(\mathcal{A}) = \text{span}(\mathcal{A}(\epsilon_1), \cdots, \mathcal{A}(\epsilon_n))  $;
  2. $  \text{rank}(\mathcal{A}) = \text{rank}(A)  $;
  3. $  \dim(R(\mathcal{A})) + \dim(\text{Ker}(\mathcal{A})) = n  $.

·

## 线性变换

- 线性变换定义：设 $  V  $ 是数域 $  \mathbb{P}  $ 上的线性空间，$  V  $ 到自身的线性映射称为 $  V  $ 上的**线性变换**。

  线性空间 $  V  $ 到自身的数乘映射 $  k  $ 称为数 $  k  $ 决定的数乘变换。当 $  k = 1  $ 时，得恒等变换；当 $  k = 0  $ 时，得零变换。

  因为线性变换是一类特殊的线性映射，所以有关线性映射的性质，对线性变换完全适用。

- 定理：设 $  n  $ 维线性空间 $  V  $ 上线性变换 $  \mathcal{A}  $ 在基 $  \epsilon_1, \epsilon_2, \cdots, \epsilon_n  $ 和 $  \epsilon_1', \epsilon_2', \cdots, \epsilon_n'  $ 下的矩阵分别为 $  A  $ 和 $  B  $，由基 $  \epsilon_1, \epsilon_2, \cdots, \epsilon_n  $ 到基 $  \epsilon_1', \epsilon_2', \cdots, \epsilon_n'  $ 的过渡矩阵为 $  P  $，则$$B = P^{-1} A P$$

- 相似定义：设 $  A, B \in \mathbb{P}^{n \times n}  $，如果存在可逆矩阵 $  P \in \mathbb{P}^{n \times n}  $ 使得$$B = P^{-1} A P$$，则称 $  A  $ 与 $  B  $ **相似**。相似也是一个等价关系

  性质：如果 $  n  $ 阶矩阵 $  A  $ 与 $  B  $ 相似，则

  1. $  A  $ 与 $  B  $ 有相同的特征多项式；
  2. $  A  $ 与 $  B  $ 有相同的特征值；
  3. $  \text{tr}(A) = \text{tr}(B)  $。



## 特征值与特征向量

- 定义：设 $  \mathcal{A}  $ 是数域 $  \mathbb{P}  $ 上线性空间 $  V  $ 的一个线性变换，如果存在 $  \lambda \in \mathbb{P}  $ 以及非零向量 $  \alpha \in V  $ 使得$$\mathcal{A}(\alpha) = \lambda \alpha$$

  则称 $  \lambda  $ 为 $  \mathcal{A}  $ 的**特征值**，并称 $  \alpha  $ 为 $  \mathcal{A}  $ 的属于（或对应于）特征值 $  \lambda  $ 的**特征向量**。

- 求解：使用特征方程进行求解

- 定义：设 $  A  $ 是数域 $  \mathbb{P}  $ 上的 $  n  $ 阶矩阵，$  \lambda  $ 是一个系数，矩阵 $  \lambda I - A  $ 称为 $  A  $ 的**特征矩阵**，其行列式 $  |\lambda I - A|  $ 称为 $  A  $ 的**特征多项式**。方程 $  |\lambda I - A| = 0  $ 称为 $  A  $ 的**特征方程**，它的根称为 $  A  $ 的**特征根（或特征值）**。

  $  \lambda  $ 代入齐次线性方程组$(\lambda I -A)x =0$所得的非零解 $  x  $ 称为 $  A  $ 对应于 $  \lambda  $ 的**特征向量**。

  如果 $  \lambda  $ 是线性变换 $  \mathcal{A}  $ 的特征值，则 $  \lambda  $ 是矩阵 $  A  $ 的特征值；反过来，如果 $  \lambda  $ 是矩阵 $  A  $ 的特征值，即 $  |\lambda I - A| = 0  $，则齐次线性方程组有非零解 $  x  $，从而非零向量$$\alpha = x_1 \epsilon_1 + x_2 \epsilon_2 + \cdots + x_n \epsilon_n$$

  满足$\mathcal{A}(a) = \lambda a$，即 $  \lambda  $ 是线性变换 $  \mathcal{A}  $ 的特征值，$  \alpha  $ 是属于特征值 $  \lambda  $ 的一个特征向量。因此，线性变换的特征值、特征向量的性质可由矩阵的特征值、特征向量的性质得到。

- 对线性空间 $  V  $ 上线性变换 $  \mathcal{A}  $ 的任一特征值 $  \lambda  $，所有满足$$\mathcal{A}(\alpha) = \lambda \alpha$$

  的向量 $  \alpha  $ 所组成的集合，也就是 $  \mathcal{A}  $ 的属于特征值 $  \lambda  $ 的全部特征向量再添上零向量所组成的集合，记为 $  V_\lambda  $，即

  $$
  V_\lambda = \{ \alpha \mid \mathcal{A}(\alpha) = \lambda \alpha, \alpha \in V \}
  $$
  对矩阵 $  A \in \mathbb{C}^{n \times n}  $，$  \lambda  $ 是 $  A  $ 的一个特征值，我们记

  $$
  V_\lambda = \{ x \mid A x = \lambda x, x \in \mathbb{C}^n \}
  $$
  则 $  V_\lambda  $ 是 $  V  $（或 $  \mathbb{C}^n  $）的一个子空间，称 $  V_\lambda  $ 为 $  \mathcal{A}  $（或 $  A  $）的属于 $  \lambda  $ 的**特征子空间**。

  显然 $  \dim(V_\lambda)  $ 就是属于 $  \lambda  $ 的线性无关特征向量的最大数目，称 $  \dim(V_\lambda)  $ 为特征值 $  \lambda  $ 的**几何重数**

  > 几何重数表示属于特征值$\lambda$的线性无关特征向量的最大数目。它反映了特征值在几何意义上的重要性，即特征向量的独立性

- 定理：设 $  A = (\alpha_{ij}) \in \mathbb{P}^{n \times n}  $，则

  $$
  |\lambda I - A| = \lambda^n + \sum_{k=1}^{n} (-1)^k b_k \lambda^{n-k}
  $$
  其中 $  b_k  $（$  k = 1, 2, \cdots, n  $）是 $  A  $ 的所有 $  k  $ 阶主子式之和，特别地

  $$b_1 = \text{tr}(A), \quad b_n = |A|$$

  > 求各阶主子式其实是非常复杂的，这只是表达形式

  由代数基本定理（$  n  $ 次多项式方程在复数域内有且仅有 $  n  $ 个根（重根按重数计算））知，$  n  $ 阶矩阵 $  A  $ 在复数域内恰有 $  n  $ 个特征值 $  \lambda_1, \lambda_2, \cdots, \lambda_n  $，其中 $  \lambda_i  $ 作为特征方程的根的重数，称为 $  \lambda_i  $ 的**代数重数**，记为 $  m_{\lambda_i}(A)  $。

  > Tips：代数重数表示特征值$\lambda$在特征多项式中出现的次数。它反映了特征值在代数意义上的重要性
  >
  > 任意特征值的几何重数不超过它的代数重数

  这里我们来判断几何重数和代数重数的关系，需要介绍一个东西：

- Jordan块

  在线性代数中，Jordan块（Jordan block）是一种特殊的方块矩阵，用于**Jordan标准形分解**。对于一个特征值λ和一个正整数n，n×n的Jordan块$J_n(λ)$定义为：

  $$
  J_n(λ) = \begin{bmatrix}    λ & 1 & 0 & \cdots & 0 \\    0 & λ & 1 & \cdots & 0 \\    0 & 0 & λ & \cdots & 0 \\    \vdots & \vdots & \vdots & \ddots & \vdots \\    0 & 0 & 0 & \cdots & λ \end{bmatrix}
  $$

  - **主对角线**上的元素都是特征值λ。
  - **主对角线上方的次对角线**上的元素都是1。
  - **其余元素**都是0。

- 矩阵 $  A  $ 的特征值的全体称为 $  A  $ 的**谱**，记为 $  \lambda(A)  $。矩阵 $  A  $ 的特征值的最大模称为 $  A  $ 的**谱半径**，记为 $  \rho(A)  $。

下面给出一个非常重要的定理，使用特征值来描述整个矩阵的特性

- 定理：设 $  A = (a_{ij}) \in \mathbb{C}^{n \times n}  $，$  \lambda_1, \lambda_2, \cdots, \lambda_n  $ 是 $  A  $ 的特征值，则

  $$
  \sum_{i=1}^{n} \lambda_i = \text{tr}(A) \\
  \prod_{i=1}^{n} \lambda_i = |A|
  $$

- $  m  $ 阶方阵 $  AB  $ 与 $  n  $ 阶方阵 $  BA  $ 具有相同的非零特征值，从而由定理 2.4.3 有 $  \text{tr}(AB) = \text{tr}(BA)  $。特别地，若 $  A, B  $ 为同阶方阵，则 $  AB  $ 与 $  BA  $ 具有相同的特征值。

  关于线性变换或矩阵的特征向量有如下结论：

  定理：设 $  \lambda_1, \lambda_2, \cdots, \lambda_r  $ 是线性变换 $  \mathcal{A}  $（或矩阵 $  A  $）的 $  r  $ 个互不相同的特征值，$  \alpha_i  $（$  i = 1, 2, \cdots, r  $）是对应于 $  \lambda_i  $ 的特征向量，则 $  \alpha_1, \alpha_2, \cdots, \alpha_r  $ 线性无关。



## 矩阵的相似对角形

- 定义：设 $  \mathcal{A}  $ 是数域 $  \mathbb{P}  $ 上 $  n  $ 维线性空间 $  V  $ 上的一个线性变换，如果 $  V  $ 中存在一组基，使得 $  \mathcal{A}  $ 在这组基下的矩阵是对角矩阵，则称 $  \mathcal{A}  $ 是**可对角化**的。
  $$
  P^{-1}AP = \Lambda = \begin{pmatrix} \lambda_1 & & & 0 \\ & \lambda_2 & & \\ & & \ddots & \\ 0 & & & \lambda_n \end{pmatrix} \equiv \text{diag}(\lambda_1, \lambda_2, \cdots, \lambda_n)
  $$

- 判断是否S可对角化：

  - 定义：如果 $  n  $ 阶矩阵 $  A  $ 与对角矩阵相似，则称矩阵 $  A  $ 是**可对角化**的。

  - 定理：数域 $  \mathbb{P}  $ 上 $  n  $ 维线性空间 $  V  $ 上的一个线性变换 $  \mathcal{A}  $ 可对角化的**充分必要条件**是 $  \mathcal{A}  $ 有 $  n  $ 个线性无关的特征向量。

  - 定理：如果数域 $  \mathbb{P}  $ 上 $  n  $ 维线性空间 $  V  $ 上的线性变换 $  \mathcal{A}  $（或 $  n  $ 阶矩阵 $  A  $）有 $  n  $ 个不同的特征值，则线性变换 $  \mathcal{A}  $（或矩阵 $  A  $）是可对角化的。

  - 定理：设数域 $  \mathbb{P}  $ 上 $  n  $ 维线性空间 $  V  $ 上线性变换 $  \mathcal{A}  $ 的互异特征值为 $  \lambda_1, \lambda_2, \cdots, \lambda_r  $，则 $  \mathcal{A}  $ 可对角化的充分必要条件是

    $$
    V = V_{\lambda_1} \oplus V_{\lambda_2} \oplus \cdots \oplus V_{\lambda_r}
    $$
    也即每个特征值的几何重数等于其代数重数



## 线性变换的不变子空间

- 定义：设 $\mathcal{A}$ 是数域 $\mathbf{P}$ 上线性空间 $V$ 的线性变换，$W$ 是 $V$ 的子空间，如果对任意 $\alpha \in W$，都有 $\mathcal{A}(\alpha) \in W$，则称 $W$ 是 $\mathcal{A}$ 的不变子空间。

  > 即对运算$\mathcal{A}$是封闭的

  - 整个线性空间$V$和零子空间$\{0\}$，是$\mathcal{A}$的平凡子空间

  类似于线性映射的值域与核，对线性空间 $V$ 上的线性变换 $\mathcal{A}$，可定义 $\mathcal{A}$ 的值域 $R(\mathcal{A})$ 和核 $\text{Ker}(\mathcal{A})$ 如下：

  $$
  R(\mathcal{A}) = \{ \mathcal{A}(\alpha) \mid \alpha \in V \} \\
  \text{Ker}(\mathcal{A}) = \{ \alpha \in V \mid \mathcal{A}(\alpha) = 0 \}
  $$

  - 线性变换 $\mathcal{A}$ 的值域 $R(\mathcal{A})$ 和核 $\text{Ker}(\mathcal{A})$ 以及其特征子空间都是 $V$ 的不变子空间
  - 线性变换的和和交都是$\mathcal{A}$的不变子空间

- 定理：设线性空间 $V$ 的子空间 $W = \text{span}(\alpha_1, \cdots, \alpha_m)$，则 $W$ 是线性变换 $\mathcal{A}$ 的不变子空间的**充分必要**条件是 $\mathcal{A}(\alpha_i) \in W$ $(i = 1, 2, \cdots, m)$

  即$W$的每个基对运算$\mathcal{A}$是封闭的

- 定理：设 $\mathcal{A}$ 是线性空间 $V$ 上的线性变换，如果 $W$ 是 $\mathcal{A}$ 的一维不变子空间，则 $W$ 中任何一个非零向量都是 $\mathcal{A}$ 的特征向量；反之，若 $\alpha$ 是 $\mathcal{A}$ 的一个特征向量，则 $\text{span}(\alpha)$ 是 $\mathcal{A}$ 的一维不变子空间。

- 定理：设 $\mathcal{A}$ 是数域 $\mathbf{P}$ 上 $n$ 维线性空间 $V$ 上的线性变换，则 $\mathcal{A}$ 在 $V$ 的一组基下的矩阵为块对角矩阵的充分必要条件是 $V$ 能分解成 $\mathcal{A}$ 的若干个非平凡不变子空间的直和。



## 酉（正交）变换与酉（正交）矩阵

本节首先介绍酉（正交）矩阵的概念及其基本性质，然后讨论内积空间中保持内积的线性变换，称之为酉（正交）变换。

- 定义：如果 $n$ 阶实矩阵 $A$ 满足$$A^\mathrm{T} A = A A^\mathrm{T} = I$$则称 $A$ 为正交矩阵。如果 $n$ 阶复矩阵 $A$ 满足$$A^\mathrm{H} A = A A^\mathrm{H} = I$$，则称 $A$ 为酉矩阵。下面给出一些性质

  根据定义容易验证：如果 $A, B$ 是正交矩阵，则

  1. $A^{-1} = A^\mathrm{T}$，且 $A^\mathrm{T}$ 也是正交矩阵；
  2. $A$ 非奇异且 $|A| = \pm 1$；
  3. $AB$ 仍是正交矩阵

  对酉矩阵也有类似的结论

- 定理：设 $A$ 是 $n$ 阶矩阵，则 $A$ 是酉（正交）矩阵的充分必要条件是 $A$ 的 $n$ 个列向量是 $\mathbf{C}^n(\mathbf{R}^n)$ 的标准正交向量组。

在内积空间中经常需要讨论与内积有关的线性变换。

- 定义：设 $\mathcal{A}$ 是 $n$ 维酉（欧氏）空间 $V$ 的线性变换，如果对任意 $\alpha, \beta \in V$ 都有
  $$
  (\mathcal{A}(\alpha), \mathcal{A}(\beta)) = (\alpha, \beta)
  $$
  则称 $\mathcal{A}$ 是 $V$ 的**酉（正交）变换**。

- 定理 ：设 $\mathcal{A}$ 是 $n$ 维酉（欧氏）空间 $V$ 的线性变换，则下列命题等价：
  1. $\mathcal{A}$ 是酉（正交）变换；
  2. $\| \mathcal{A}(\alpha) \| = \| \alpha \|, \, \forall \, \alpha \in V$；
  3. 如果 $\varepsilon_1, \cdots, \varepsilon_n$ 是 $V$ 的一组标准正交基，则 $\mathcal{A}(\varepsilon_1), \cdots, \mathcal{A}(\varepsilon_n)$ 也是 $V$ 的一组标准正交基；
  4. $\mathcal{A}$ 在 $V$ 的任意一组标准正交基下的矩阵是酉（正交）矩阵。



# 矩阵的性能指标

一个$m\times n$的矩阵含有$m\times n$个元素，我们希望使用几个标量来概括这个多变量表示，这里介绍概括矩阵性质的几个重要的标量指标

- 矩阵的二次型

  任意一个正方矩阵 $  A  $ 的二次型定义为 $  x^H A x  $，其中 $  x  $ 可以是任意的非零复向量。
  以实矩阵为例，考查二次型

  $$
  x^T A x = [x_1, x_2, x_3] \begin{bmatrix}1 & 4 & 2 \\-1 & 7 & 5 \\-1 & 6 & 3\end{bmatrix}\begin{bmatrix}x_1 \\x_2 \\x_3\end{bmatrix} \\
  = x_1^2 + 7x_2^2 + 3x_3^2 + 3x_1 x_2 + x_1 x_3 + 11x_2 x_3
  $$
  这是变元 $  x  $ 的二次型函数，故称 $  x^T A x  $ 为矩阵 $  A  $ 的二次型。

  推而广之，若 $  x = [x_1, \cdots, x_n]^T  $，且 $  n \times n  $ 矩阵 $  A  $ 的元素为 $  a_{ij}  $，则二次型

  $$
  x^T A x = \sum_{i=1}^{n} \sum_{j=1}^{n} x_i x_j a_{ij} = \sum_{i=1}^{n} a_{ii} x_i^2 + \sum_{i=1}^{n} \sum_{j=i+1}^{n} a_{ij} x_i x_j \\
  = \sum_{i=1}^{n} a_{ii} x_i^2 + \sum_{1 \leq i < j \leq n} (a_{ij} + a_{ji}) x_i x_j
  $$
  许多矩阵满足相同的二次型，但是只有**唯一的对称矩阵**$A$​满足该二次型。因此在讨论二次型时，有必要假定 $  A  $ 为实对称矩阵或复共轭对称（即 Hermitian）矩阵。这一假定还能够保证二次型函数一定是实值函数，因为 $  (x^H A x)^* = (x^H A x)^H = x^H A^H x = x^H A x  $ 对任意复共轭对称矩阵 $  A  $ 和非零复向量 $  x  $ 均成立。

  > 实值函数的基本优点之一是适合于同零值比较大小。

  也通过二次型刻画矩阵的正定性

- 行列式

  行列式主要刻画矩阵的奇异性

- 矩阵的特征值

  - 特征值能刻画原矩阵的奇异性

    非奇异矩阵特征值全不为0

  - 反映原矩阵所有对角元素的结构

    奇异矩阵的所有对角元素同时减去相同的非零特征值得到的矩阵仍然是奇异矩阵

    非奇异矩阵阵的所有对角元素同时减去相同的非零特征值得到的矩阵一定是奇异矩阵

  - 刻画矩阵的正定性

    整定矩阵的所有特征值都是正实数

- 矩阵的迹

  $tr(A)$为矩阵的迹，非正方矩阵无迹的定义。

  矩阵的迹有很多性质，利用它们可以得到很多重要的结论，比如：

  1. 矩阵的迹等于特征值的和$tr(A) = \lambda_1+\cdots +\lambda_n$
  2. $tr(AB) =tr(BA)$
  3. 若B非奇异则有$tr(BAB^{-1}) = tr(A)$

  矩阵的迹反映所有特征值的和

- 矩阵的秩

  适定，欠定，超定方程

  秩刻画矩阵行与行之间或者列与列之间的线性无关性，从而反映矩阵的满秩性和秩亏缺性



# 矩阵的逆

- 逆矩阵

  - 引理 (Sherman-Morrison 公式) 令 $  A  $ 是一个 $  n \times n  $ 的可逆矩阵，并且 $  x  $ 和 $  y  $是两个 $  n \times 1  $ 向量，使得 $  (A + xy^H)  $ 可逆，则
    $$
    (A + xy^H)^{-1} = A^{-1} - \frac{A^{-1} xy^H A^{-1}}{1 + y^H A^{-1} x}
    $$

  - Woodbury公式：

    矩阵求逆引理可以推广为矩阵之和的求逆公式

    $$
    (A + UBV)^{-1} = A^{-1} - A^{-1}UB(B + BVA^{-1}UB)^{-1}BVA^{-1} \\
    = A^{-1} - A^{-1}U(I + BVA^{-1}U)^{-1}BVA^{-1}
    $$
    或者

    $$
    (A - UV)^{-1} = A^{-1} + A^{-1}U(I - VA^{-1}U)^{-1}VA^{-1}
    $$

- 左伪逆和右伪逆

  - 定义：满足 $  LA = I  $，但不满足 $  AL = I  $ 的矩阵 $  L  $ 称为矩阵 $  A  $ 的左逆矩阵 (left inverse)。类似地，满足 $  AR = I  $，但不满足 $  RA = I  $ 的矩阵称为矩阵 $  A  $ 的右逆矩阵 (right inverse)。

    1. 仅当 $  m \geq n  $ 时，矩阵 $  A \in \mathbb{C}^{m \times n}  $ 可能有左逆矩阵（可能多个）。
    2. 仅当 $  m \leq n  $ 时，矩阵 $  A \in \mathbb{C}^{m \times n}  $ 可能有右逆矩阵（可能多个）。

  - 下面考虑左右逆矩阵的唯一解

    - 左伪逆矩阵：考察 $  m > n  $ 并且 $  A  $ 具有满列秩 (rank $  A = n  $) 的情况。此时，$  n \times n  $ 矩阵 $  A^H A  $ 是可逆的。容易验证

      $$
      L = (A^H A)^{-1} A^H
      $$
      满足左逆矩阵的定义 $  LA = I  $。这种左逆矩阵是唯一确定的，常称为左伪逆矩阵 (left pseudo inverse)。

      常与超定方程的最小二乘解相关

    - 右伪逆矩阵：考察 $  m < n  $ 并且 $  A  $ 具有满行秩 (rank $  A = m  $) 的情况。此时，$  m \times m  $ 矩阵 $  AA^H  $ 是可逆的。定义

      $$
      R = A^H (AA^H)^{-1}
      $$
      不难验证，它满足右逆矩阵的定义 $  AR = I  $。这一特殊的右逆矩阵也是唯一确定的，常称为右伪逆矩阵 (right pseudo inverse)。

      常与欠定方程的最小二乘最小范数解相关

- Moore-Penrose逆矩阵

  上面讨论了方阵的逆，以及行满秩或者列满秩的伪逆，那么一个秩亏缺的矩阵是否存在逆矩阵？——有的，称为广义逆矩阵（推导定义还挺麻烦）

  - 定义：令 $  A  $ 是任意 $  m \times n  $ 矩阵，称矩阵 $  A^\dagger  $ 是 $  A  $ 的广义逆矩阵，若 $  A^\dagger  $ 满足以下四个条件（常称 Moore-Penrose 条件）：

    1. $  AA^\dagger A = A  $;
    2. $  A^\dagger A A^\dagger = A^\dagger  $;
    3. $  AA^\dagger  $ 为 Hermitian 矩阵，即 $  AA^\dagger = (AA^\dagger)^H  $;
    4. $  A^\dagger A  $ 为 Hermitian 矩阵，即 $  A^\dagger A = (A^\dagger A)^H  $。

    > 历史上Moore先提出了广义逆矩阵$A^{\dagger}$的两个条件，但是不易于使用，然后Penrose提出四条件，两者条件是等价的

    上面介绍的各种矩阵都是广义逆矩阵的特例

    任意一个 $  m \times n  $ 矩阵 $  A  $ 的 Moore-Penrose 逆矩阵都可以由

    $$
    A^\dagger = (A^H A)^\dagger A^H \quad (\text{若 } m \geq n)
    $$
    或者

    $$
    A^\dagger = A^H (A A^H)^\dagger \quad (\text{若 } m \leq n)
    $$

  - 下面给出$A^\dagger$的计算方法

    - 方程求解法：

      - 法一：
        1. 计算矩阵 $  B = AA^H  $。
        2. 求解矩阵方程 $  B^2 X^H = B  $ 得到矩阵 $  X^H  $。
        3. 计算 $  B  $ 的 Moore-Penrose 逆矩阵 $  B^\dagger = (AA^H)^\dagger = XB X^H  $。
        4. 计算矩阵 $  A  $ 的 Moore-Penrose 逆矩阵 $  A^\dagger = A^H (AA^H)^\dagger = A^H B^\dagger  $。
      - 法二

    - 满秩分解法

      令秩亏缺矩阵 $  A_{m \times n}  $ 具有秩 $  r < \min\{m, n\}  $。若 $  A = FG  $，其中，$  F_{m \times r}  $ 的秩为 $  r  $（满列秩矩阵），且 $  G_{r \times n}  $ 的秩也为 $  r  $（满行秩矩阵），则称 $  A = FG  $ 为矩阵 $  A  $ 的满秩分解 (full-rank decomposition)。

    - 递推法

    - 迹方法

- 非一致方程的最小范数最小二乘解

  > **非一致方程**（或称为 **不相容方程**）通常指的是在数学（特别是线性代数）中，**没有解的方程**或**方程组**。具体来说，对于一个线性方程组$Ax=b$，如果不存在向量 *x* 使得方程成立，那么称该方程组是 **非一致的**

  前面讨论过一致方程 $  Ax = y  $ 的最小范数解 $  x = A^H (AA^H)^{-1} b  $ 和非一致方程 $  Ax = y  $ 的最小二乘解 $  x = (A^H A)^{-1} A^H b  $。注意，当矩阵 $  A  $ 秩亏缺时，非一致方程 $  Ax = y  $ 的最小二乘解不是唯一的。此时，往往希望适当选择一个广义逆矩阵，以便在最小二乘解中获得一个具有最小范数的解。这样一种解称为非一致方程 $  Ax = y  $ 的最小范数最小二乘解（minimum norm least squares solution）。

  - 定义：对于非一致方程 $  A_{m \times n} x_{n \times 1} = y_{m \times 1}  $，解 $  Gy  $ 称为 $  Ax = y  $ 的最小范数最小二乘解，若
    $$
    \|Gy\|_n \leq \|\hat{x}\|_n \quad \forall \, \hat{x} \in \{ \hat{x} : \|A\hat{x} - y\|_m \leq \|Az - y\|_m, \, \forall \, z \in \mathbb{R}^m, z \in \mathbb{R}^n \}
    $$
    式中，$  \|\cdot\|_n  $ 和 $  \|\cdot\|_m  $ 分别是在 $  \mathbb{R}^n  $ 和 $  \mathbb{R}^m  $ 空间的范数；花括号 $  \{\cdot\}  $ 表示 $  \hat{x}  $ 是非一致方程 $  Ax = y  $ 的最小二乘解，而 $  \|Gy\|_n \leq \|\hat{x}\|_n  $ 表示 $  Gy  $ 是在所有的最小二乘解中具有最小范数的那个解。

  - 定理：广义逆矩阵 $  G  $ 使得 $  Gy  $ 是非一致方程 $  Ax = y  $ 的最小范数最小二乘解，当且仅当 $  G  $ 满足条件
    $$
    AGA = A, \quad (AG)^\# = AG, \quad GAG = G, \quad (GA)^\# = GA
    $$
    式中，$  A^\#  $ 是 $  A  $ 的伴随矩阵。

    利用伴随矩阵的性质 $  B^\# = B^H  $ 易知，定理也可以等价表述为：矩阵 $  G  $ 使得 $  Gy  $ 是非一致方程 $  Ax = y  $ 的最小范数最小二乘解，当且仅当 $  G  $ 是 $  A  $ 的 Moore-Penrose 逆矩阵。

  





# Appendix

- sheet 1：几种向量空间的比较：

  | 几种向量空间   | 定义                                                         |
  | -------------- | ------------------------------------------------------------ |
  | 向量空间       | 定义了向量的加法和向量的数乘，以向量为元素的集合 $  \mathbb{R}^n  $ 或 $  \mathbb{C}^n  $ |
  | 内积向量空间   | 定义了内积 $  \langle x, y \rangle  $（向量的乘法）的向量空间 |
  | 赋范向量空间   | 定义了范数 $  \| x \|  $ 的向量空间，可度量向量的长度、距离与邻域 |
  | Banach 空间    | 满足 $  \lim_{n \to \infty} v_n = v, \forall v_n, v \in \mathbb{C}^n  $ 的完备赋范向量空间 |
  | Hilbert 空间   | 满足 $  \lim_{n \to \infty} \| v_n \| = \| v \|, \forall v_n, v \in \mathbb{C}^n  $ 的完备赋范向量空间 |
  | Euclidean 空间 | 具有 Euclidean 范数 $  \| x \|_2  $ 的赋范向量空间           |

  



# References

- [矩阵论近七年历年卷整合翻新，资料以及A4纸分享 - CC98论坛](https://www.cc98.org/topic/5753179)
- 【矩阵分析第一讲 什么是矩阵分析 线性系统】https://www.bilibili.com/video/BV1p44y1h78d?vd_source=b38d40e4ee48a659bc5c5113dcf1c249
- [矩阵论大作业（图像去噪）及A4分享 - CC98论坛](https://www.cc98.org/topic/6043432)